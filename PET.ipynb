{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demelin/ai_reimplementations/blob/main/PET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtvm_LTRsmnI"
      },
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dLuOXbcZ_UZ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import trange, tqdm\n",
        "from torch.utils.data import (\n",
        "    Dataset, DataLoader, RandomSampler, SequentialSampler)\n",
        "from transformers import (\n",
        "    AutoConfig, AutoTokenizer, AutoModelForPreTraining,\n",
        "    AutoModelForSequenceClassification, get_linear_schedule_with_warmup)\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-1AJoOQuQ6e"
      },
      "outputs": [],
      "source": [
        "# Load and sample data\n",
        "\n",
        "class DataInitializer(object):\n",
        "\n",
        "  \"\"\" Downloads the Yelp data from the HUggingFace repository and prepares\n",
        "  it for model use. \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      dataset_name\n",
        "      ):\n",
        "\n",
        "    self.dataset_name = dataset_name\n",
        "    (self.train_text, self.train_labels,\n",
        "     self.eval_text, self.eval_labels) = self._fetch_data()\n",
        "\n",
        "  def _fetch_data(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    \"\"\" Downloads datasets from HuggingFace. \"\"\"\n",
        "\n",
        "    raw_train_data = load_dataset(self.dataset_name, split=\"train\")\n",
        "    raw_test_data = load_dataset(self.dataset_name, split=\"test\")\n",
        "\n",
        "    return [raw_train_data[\"text\"][:], raw_train_data[\"label\"][:],\n",
        "            raw_test_data[\"text\"][:], raw_test_data[\"label\"][:]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JM8KDD7uYC-"
      },
      "outputs": [],
      "source": [
        "# Define PVP for Yelp data\n",
        "\n",
        "class YelpPVPVerbalizer(object):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      tokenizer\n",
        "      ):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "    # Declare PVPs to be used with the data\n",
        "    # (last element denotes the segment and position containing the text token)\n",
        "    self.pattern_dict = {\n",
        "        0: [[\"It was \", \"<|MASK|>\", \". \", \"<|TEXT|>\"], [], (0, 3)],\n",
        "        1: [[\"Just \", \"<|MASK|>\", \"! \"], [\"<|TEXT|>\"], (1, 0)],\n",
        "        2: [[\"<|TEXT|>\", \"All in all, it was \", \"<|MASK|>\", \".\"], [], (0, 0)],\n",
        "        3: [[\"<|TEXT|>\"], [\"In summary, the restaurant is \", \"<|MASK|>\", \".\"],\n",
        "         (0, 0)]\n",
        "        }\n",
        "\n",
        "    # Pre-tokenize pattern segments and compute pattern lengths for truncation\n",
        "    self.pattern_segment_dict = dict()\n",
        "    self.pattern_text_length = dict()\n",
        "\n",
        "    for key in self.pattern_dict.keys():\n",
        "      self.pattern_segment_dict[key] = list()\n",
        "      self.pattern_text_length[key] = 0\n",
        "\n",
        "      for lst in self.pattern_dict[key][:-1]:\n",
        "        if len(lst) == 0:\n",
        "          self.pattern_segment_dict[key].append(lst)\n",
        "        else:\n",
        "          token_list = list()\n",
        "          for seg in lst:\n",
        "            if seg == \"<|TEXT|>\":\n",
        "              token_list.append(seg)\n",
        "            elif seg == \"<|MASK|>\":\n",
        "              token_list.append([self.tokenizer.mask_token_id])\n",
        "              self.pattern_text_length[key] += 1\n",
        "            else:\n",
        "              phrase_tokens = self.tokenizer.encode(\n",
        "                  seg, add_special_tokens=False)\n",
        "              token_list.append(phrase_tokens)\n",
        "              self.pattern_text_length[key] += len(phrase_tokens)\n",
        "\n",
        "          self.pattern_segment_dict[key].append(token_list)\n",
        "\n",
        "    # Declare labels and their corresponding verbalizations\n",
        "    # NOTE: \"terrible\" and \"okay\", the original verbalizations of the \"1\" and\n",
        "    # \"3\" labels, are split in two tokens making them unsuitable as PET labels;\n",
        "    # using \"grim\" and \"ok\" instead\n",
        "    self.label_dict = {\n",
        "        0: \"grim\",\n",
        "        1: \"bad\",\n",
        "        2: \"ok\",\n",
        "        3: \"good\",\n",
        "        4: \"great\"\n",
        "        }\n",
        "\n",
        "    # Sanity check\n",
        "    for lbl in self.label_dict.values():\n",
        "      lbl_id = self.tokenizer.convert_tokens_to_ids(lbl)\n",
        "      assert lbl_id != self.tokenizer.unk_token_id, \"{:s} does not map to a single token!\".format(lbl)\n",
        "\n",
        "    # Create a tensor of token_ids corresponding to label verbalization\n",
        "    # for evaluating model predictions\n",
        "    self.label_token_ids = torch.tensor(self.tokenizer.convert_tokens_to_ids(\n",
        "        [\"grim\", \"bad\", \"okay\", \"good\", \"great\"]))\n",
        "\n",
        "    # If a pattern has two segments, tokenizer will add special tokens\n",
        "    self.num_special_tokens_added_single = self.tokenizer.num_special_tokens_to_add(pair=False)\n",
        "    self.num_special_tokens_added_pair = self.tokenizer.num_special_tokens_to_add(pair=True)\n",
        "\n",
        "\n",
        "  def verbalize_and_encode_sample(\n",
        "      self,\n",
        "      sample,\n",
        "      pattern_id,\n",
        "      max_seq_len\n",
        "      ):\n",
        "\n",
        "    \"\"\" Transforms a Yelp sample by filling the specified pattern. \"\"\"\n",
        "\n",
        "    # Select pattern\n",
        "    pattern = self.pattern_dict[pattern_id][:-1]\n",
        "    text_segment_id, text_position = self.pattern_dict[pattern_id][-1]\n",
        "    # Tokenize and truncate sample\n",
        "    token_ids = self.tokenizer.encode(sample[\"text\"], add_special_tokens=False)\n",
        "    # Adjust maximum length for special tokens\n",
        "    if min([len(s) for s in pattern]) > 0:\n",
        "      max_seq_len -= (self.num_special_tokens_added_pair +\n",
        "                      self.pattern_text_length[pattern_id])\n",
        "    else:\n",
        "      max_seq_len -= (self.num_special_tokens_added_single +\n",
        "                      self.pattern_text_length[pattern_id])\n",
        "\n",
        "    # Truncate by substracting the length of special tokens and pattern parts\n",
        "    token_ids = token_ids[:max_seq_len]\n",
        "    # Add to tokenized pattern\n",
        "    pattern_tokens = self.pattern_segment_dict[pattern_id]\n",
        "    pattern_tokens[text_segment_id][text_position] = token_ids\n",
        "    # Merge\n",
        "    merged_pattern_tokens = [[], []]\n",
        "    for lst_id, lst in enumerate(pattern_tokens):\n",
        "      for part in pattern_tokens[lst_id]:\n",
        "        merged_pattern_tokens[lst_id] += part\n",
        "\n",
        "    # Encode verbalized sample\n",
        "    encoded_filled_pattern_segments = self.tokenizer.build_inputs_with_special_tokens(\n",
        "        merged_pattern_tokens)\n",
        "    encoded_filled_pattern = []\n",
        "    for seg in encoded_filled_pattern_segments:\n",
        "      if type(seg) == list:\n",
        "        encoded_filled_pattern += seg\n",
        "        # Add separator token after each list if pattern has two segments\n",
        "        if min([len(s) for s in pattern]) > 0:\n",
        "          encoded_filled_pattern += [self.tokenizer.sep_token_id]\n",
        "      else:\n",
        "        encoded_filled_pattern += [seg]\n",
        "\n",
        "    return {\"token_ids\": encoded_filled_pattern, \"label\": sample[\"label\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyBKiwsZxhfI"
      },
      "outputs": [],
      "source": [
        "class NewDataset(Dataset):\n",
        "\n",
        "    \"\"\" Dataset object for model training. \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_ids,\n",
        "        attention_masks,\n",
        "        labels,\n",
        "        labels_arrays\n",
        "        ):\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "        self.labels_arrays = labels_arrays\n",
        "\n",
        "    def __len__(\n",
        "        self\n",
        "        ):\n",
        "\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        item_id\n",
        "        ):\n",
        "\n",
        "        input_ids = self.input_ids[item_id]\n",
        "        attention_mask = self.attention_masks[item_id]\n",
        "        label = self.labels[item_id]\n",
        "        labels_array = self.labels_arrays[item_id] if self.labels_arrays[\n",
        "            item_id] is not None else [-1]\n",
        "        sample = {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"label\": label,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels_array\": labels_array\n",
        "            }\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "\n",
        "  \"\"\" Prepares data for use with the MLM. \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      config,\n",
        "      data_initializer,\n",
        "      tokenizer,\n",
        "      verbalizer\n",
        "      ):\n",
        "\n",
        "    self.config = config\n",
        "    self.data_initializer = data_initializer\n",
        "    self.tokenizer = tokenizer\n",
        "    self.verbalizer = verbalizer\n",
        "    self.labels_list = list(self.verbalizer.label_dict.keys())\n",
        "    self.num_labels = len(self.labels_list)\n",
        "\n",
        "    # Prepare data\n",
        "    self.train_data_per_label = self._transform_data(\n",
        "        self.data_initializer.train_text, self.data_initializer.train_labels)\n",
        "    self.eval_data_per_label = self._transform_data(\n",
        "        self.data_initializer.eval_text, self.data_initializer.eval_labels)\n",
        "\n",
        "\n",
        "  def _transform_data(\n",
        "      self,\n",
        "      inputs,\n",
        "      labels\n",
        "      ):\n",
        "\n",
        "      \"\"\" Performs pre-processing on the fetched data. \"\"\"\n",
        "\n",
        "      def _preprocess_text(text):\n",
        "\n",
        "        \"\"\" Helper applying minimal pre-processing to the sample text by\n",
        "        removing newlines. \"\"\"\n",
        "\n",
        "        return text.replace('\\\\', ' ')\n",
        "\n",
        "      # Convert training data into a {label: [samples]} dict\n",
        "      data_per_label = dict()\n",
        "      print(\"Transforming samples ...\")\n",
        "\n",
        "      for lbl_id, lbl in enumerate(labels):\n",
        "        # Apply preprocessing\n",
        "        preprocessed_text = _preprocess_text(inputs[lbl_id])\n",
        "        sample_dict = {\n",
        "            \"sample_id\": \"{:d}_{:d}\".format(lbl, lbl_id),\n",
        "            \"text\": preprocessed_text,\n",
        "            \"label\": lbl\n",
        "            }\n",
        "        if lbl not in data_per_label.keys():\n",
        "          data_per_label[lbl] = [sample_dict]\n",
        "        else:\n",
        "          data_per_label[lbl].append(sample_dict)\n",
        "\n",
        "      print(\"Done!\")\n",
        "\n",
        "      # Free up RAM\n",
        "      del inputs\n",
        "      del labels\n",
        "\n",
        "      return data_per_label\n",
        "\n",
        "\n",
        "  def _get_samples(\n",
        "      self,\n",
        "      data_per_label,\n",
        "      num_samples_per_label,\n",
        "      sample_ids_to_exclude=[]\n",
        "      ):\n",
        "\n",
        "      \"\"\" Samples the specified number of samples from the training data. \"\"\"\n",
        "\n",
        "      collected_samples = {l: list() for l in self.labels_list}\n",
        "\n",
        "      for lbl in self.labels_list:\n",
        "        # Shuffle data\n",
        "        random.shuffle(data_per_label[lbl])\n",
        "\n",
        "        # Sample samples, excluding datapoints based on ID (if specified) to\n",
        "        # prevent overlap between labeled and unlabelled data\n",
        "        if len(sample_ids_to_exclude) == 0:\n",
        "          collected_samples[lbl] = data_per_label[lbl][:num_samples_per_label]\n",
        "        else:\n",
        "          collected_samples[lbl] = list()\n",
        "          for i in range(num_samples_per_label):\n",
        "            if data_per_label[lbl][i][\"sample_id\"] not in sample_ids_to_exclude:\n",
        "              collected_samples[lbl].append(data_per_label[lbl][i])\n",
        "            else:\n",
        "              continue\n",
        "\n",
        "      return collected_samples\n",
        "\n",
        "\n",
        "  def sample_data(\n",
        "      self,\n",
        "      data_per_label,\n",
        "      num_samples_per_label,\n",
        "      is_eval=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Samples data to be used with models. \"\"\"\n",
        "\n",
        "    # Sample labeled data for model training\n",
        "    labeled_samples = self._get_samples(data_per_label, num_samples_per_label)\n",
        "    unlabeled_samples = list()\n",
        "\n",
        "    if not is_eval:\n",
        "      # Prevent overlap between the two sets of samples\n",
        "      labeled_sample_ids = list()\n",
        "      for lbl in labeled_samples.keys():\n",
        "        for ps in labeled_samples[lbl]:\n",
        "          labeled_sample_ids.append(ps[\"sample_id\"])\n",
        "      unlabeled_samples = self._get_samples(\n",
        "          data_per_label, self.config.num_unlabeled_sampes_per_label,\n",
        "          labeled_sample_ids)\n",
        "\n",
        "    return labeled_samples, unlabeled_samples\n",
        "\n",
        "\n",
        "  def _verbalize_and_encode_data(\n",
        "      self,\n",
        "      pattern_id,\n",
        "      labeled_samples,\n",
        "      unlabeled_samples\n",
        "      ):\n",
        "\n",
        "    \"\"\" Generates data to be used for model training and evaluation. \"\"\"\n",
        "\n",
        "    # Verbalize and encode all samples\n",
        "    encoded_labeled_samples = list()\n",
        "    encoded_unlabeled_samples = list()\n",
        "\n",
        "    if len(unlabeled_samples) > 0:\n",
        "      all_samples = [labeled_samples, unlabeled_samples]\n",
        "    else:\n",
        "      all_samples = [labeled_samples]\n",
        "\n",
        "    for samples_id, samples in enumerate(all_samples):\n",
        "      if samples_id == 0:\n",
        "        print(\"Verbalizing PET samples ...\")\n",
        "        encoded_samples = encoded_labeled_samples\n",
        "      else:\n",
        "        print('Verbalizing unlabeled samples ...')\n",
        "        encoded_samples = encoded_unlabeled_samples\n",
        "\n",
        "      # Ensure sequential dataloaders always have the same data sequence\n",
        "      samples_keys = sorted(list(samples.keys()))\n",
        "      samples_seen = 0\n",
        "      for label in samples.keys():\n",
        "        for sample_id, sample in enumerate(samples[label]):\n",
        "          es = self.verbalizer.verbalize_and_encode_sample(\n",
        "              sample, pattern_id, self.config.max_seq_len)\n",
        "          encoded_samples.append(es)\n",
        "          samples_seen += 1\n",
        "\n",
        "        if (samples_seen) % 1000 == 0:\n",
        "          print(\"\\tProcessed {:d} samples\".format(samples_seen))\n",
        "\n",
        "    return encoded_labeled_samples, encoded_unlabeled_samples\n",
        "\n",
        "\n",
        "  def _encode_data(\n",
        "      self,\n",
        "      samples_per_label\n",
        "      ):\n",
        "\n",
        "    \"\"\" Encodes non-verbalized data. \"\"\"\n",
        "\n",
        "    encoded_labeled_samples = list()\n",
        "\n",
        "    for pattern_id in self.verbalizer.pattern_dict.keys():\n",
        "       for sample_id, sample in enumerate(samples_per_label[pattern_id]):\n",
        "        # Tokenize and truncate sample\n",
        "        token_ids = self.tokenizer.encode(\n",
        "            sample[\"text\"], add_special_tokens=False)\n",
        "        token_ids = token_ids[:self.config.max_seq_len -\n",
        "                              self.verbalizer.num_special_tokens_added_single]\n",
        "        token_ids = self.tokenizer.build_inputs_with_special_tokens(token_ids)\n",
        "        encoded_labeled_samples.append({\n",
        "            \"token_ids\": token_ids,\n",
        "            \"label\": sample[\"label\"]\n",
        "            })\n",
        "\n",
        "    return encoded_labeled_samples\n",
        "\n",
        "\n",
        "  def _add_masks_and_padding(\n",
        "      self,\n",
        "      samples,\n",
        "      is_pet_sample=True\n",
        "      ):\n",
        "\n",
        "    \"\"\" Prepares data for use with the trained / evaluated model. \"\"\"\n",
        "\n",
        "    for smp in samples:\n",
        "      seq_len = len(smp[\"token_ids\"])\n",
        "      # 1. Construct attention mask\n",
        "      smp[\"attention_mask\"] = [1] * seq_len\n",
        "\n",
        "      # 2. Pad sequences to max_seq_len if necessary\n",
        "      pad_size = self.config.max_seq_len - len(smp[\"token_ids\"])\n",
        "      if pad_size > 0:\n",
        "          smp[\"token_ids\"] += [self.tokenizer.pad_token_id] * pad_size\n",
        "          smp[\"attention_mask\"] += [0] * pad_size\n",
        "\n",
        "      # 3. Create training labels\n",
        "      if is_pet_sample:\n",
        "        # Label for the MLM objective\n",
        "        pet_labels = [0] * self.num_labels\n",
        "        pet_labels[smp[\"label\"]] = 1\n",
        "        smp[\"labels_array\"] = pet_labels\n",
        "      else:\n",
        "        smp[\"labels_array\"] = []\n",
        "\n",
        "    return samples\n",
        "\n",
        "\n",
        "  def _convert_sample_to_model_inputs(\n",
        "      self,\n",
        "      samples\n",
        "      ):\n",
        "\n",
        "    \"\"\" Converts an encoded sample into a format usable by the LM. \"\"\"\n",
        "\n",
        "    # sample is a dictionary with keys:\n",
        "    # [\"token_ids\", \"attention_mask\", \"label\"(is int), \"pet_label_tensor\"]\n",
        "    # - unlabeled_data does not require labels\n",
        "    feature_dict = {\n",
        "        \"input_ids\": torch.tensor(\n",
        "            [s[\"token_ids\"] for s in samples], dtype=torch.long),\n",
        "        \"attention_masks\": torch.tensor(\n",
        "            [s[\"attention_mask\"] for s in samples], dtype=torch.long),\n",
        "        \"labels\": torch.tensor(\n",
        "            [s[\"label\"] for s in samples], dtype=torch.long),\n",
        "        \"labels_arrays\": torch.tensor(\n",
        "            [s[\"labels_array\"] for s in samples], dtype=torch.long)}\n",
        "\n",
        "    return NewDataset(feature_dict[\"input_ids\"],\n",
        "                      feature_dict[\"attention_masks\"],\n",
        "                      feature_dict[\"labels\"],\n",
        "                      feature_dict[\"labels_arrays\"])\n",
        "\n",
        "\n",
        "  def get_dataloader(\n",
        "      self,\n",
        "      pattern_id,\n",
        "      labeled_samples,\n",
        "      unlabeled_samples,\n",
        "      train_batch_size,\n",
        "      eval_batch_size,\n",
        "      use_mlm_training=False,\n",
        "      is_eval=False,\n",
        "      get_sequential_unlabeled_data=False,\n",
        "      no_verbalization=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Creates a dataloader for labeled PET samples. \"\"\"\n",
        "\n",
        "    # Random dataloader for training\n",
        "    unlabeled_samples = [] if unlabeled_samples is None else unlabeled_samples\n",
        "    if not is_eval:\n",
        "      if not no_verbalization:\n",
        "        labeled_samples, unlabeled_samples = self._verbalize_and_encode_data(\n",
        "            pattern_id, labeled_samples, unlabeled_samples)\n",
        "      else:\n",
        "        # Required for training supervised models\n",
        "        labeled_samples = self._encode_data(labeled_samples)\n",
        "\n",
        "      (labeled_dataloader, unlabeled_dataset, unlabeled_dataloader,\n",
        "       seq_unlabeled_dataloader) = None, None, None, None\n",
        "\n",
        "      if len(labeled_samples) > 0:\n",
        "        padded_labeled_samples = self._add_masks_and_padding(\n",
        "            labeled_samples, is_pet_sample=(not no_verbalization))\n",
        "        labeled_dataset = self._convert_sample_to_model_inputs(\n",
        "            padded_labeled_samples)\n",
        "        labeled_sampler = RandomSampler(labeled_dataset)\n",
        "        labeled_dataloader = DataLoader(labeled_dataset,\n",
        "                                        sampler=labeled_sampler,\n",
        "                                        batch_size=train_batch_size)\n",
        "\n",
        "      if use_mlm_training or get_sequential_unlabeled_data:\n",
        "        assert unlabeled_samples is not None, \"Unlabeled samples required for auxiliary MLM training!\"\n",
        "        padded_unlabeled_samples = self._add_masks_and_padding(\n",
        "            unlabeled_samples, is_pet_sample=False)\n",
        "        unlabeled_dataset = self._convert_sample_to_model_inputs(\n",
        "            padded_unlabeled_samples)\n",
        "\n",
        "        if use_mlm_training:\n",
        "          unlabeled_sampler = RandomSampler(unlabeled_dataset)\n",
        "          unlabeled_dataloader = DataLoader(unlabeled_dataset,\n",
        "                                            sampler=unlabeled_sampler,\n",
        "                                            batch_size=self.config.mlm_batch_size)\n",
        "        if get_sequential_unlabeled_data:\n",
        "          seq_unlabeled_sampler = SequentialSampler(unlabeled_dataset)\n",
        "          seq_unlabeled_dataloader = DataLoader(unlabeled_dataset,\n",
        "                                                sampler=seq_unlabeled_sampler,\n",
        "                                                batch_size=eval_batch_size)\n",
        "\n",
        "    else:\n",
        "      # Sequential dataloader for evaluation\n",
        "      if not no_verbalization:\n",
        "        labeled_samples, _ = self._verbalize_and_encode_data(\n",
        "            pattern_id, labeled_samples, [])\n",
        "      else:\n",
        "        labeled_samples = self._encode_data(labeled_samples)\n",
        "\n",
        "      padded_labeled_samples = self._add_masks_and_padding(\n",
        "          labeled_samples, is_pet_sample=(not no_verbalization))\n",
        "      labeled_dataset = self._convert_sample_to_model_inputs(\n",
        "          padded_labeled_samples)\n",
        "      labeled_sampler = SequentialSampler(labeled_dataset)\n",
        "      labeled_dataloader = DataLoader(labeled_dataset,\n",
        "                                      sampler=labeled_sampler,\n",
        "                                      batch_size=eval_batch_size)\n",
        "      unlabeled_dataloader, seq_unlabeled_dataloader = None, None\n",
        "\n",
        "    return labeled_dataloader, unlabeled_dataloader, seq_unlabeled_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26b1Av0Vuea3"
      },
      "outputs": [],
      "source": [
        "# Define experiment configuration\n",
        "\n",
        "\n",
        "class Config(object):\n",
        "\n",
        "  \"\"\" Contains default settings for model training and evaluation. \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      max_seq_len=256,\n",
        "      train_batch_size=1,\n",
        "      eval_batch_size=8,\n",
        "      mlm_batch_size=3,\n",
        "      gradient_accumulation_steps=4,\n",
        "      num_train_steps=250,\n",
        "      learning_rate=1e-5,\n",
        "      weight_decay=0.01,\n",
        "      adam_epsilon=1e-8,\n",
        "      max_grad_norm=1.0,\n",
        "      num_unlabeled_sampes_per_label=10000,\n",
        "      cls_max_seq_len=256,\n",
        "      cls_train_batch_size=64,\n",
        "      cls_eval_batch_size=128,\n",
        "      cls_gradient_accumulation_steps=4,\n",
        "      cls_num_train_steps=1000,\n",
        "      cls_learning_rate=1e-5,\n",
        "      cls_weight_decay=0.01,\n",
        "      cls_adam_epsilon=1e-8,\n",
        "      cls_max_grad_norm=1.0,\n",
        "      pet_cls_train_batch_size=32,\n",
        "      pet_cls_eval_batch_size=64,\n",
        "      pet_models_per_pattern=3,\n",
        "      pet_alpha=10**-4,\n",
        "      pet_temperature=2,\n",
        "      ipet_num_generations=3,\n",
        "      ipet_models_fraction=0.25,\n",
        "      ipet_train_scale_factor=5,\n",
        "      ipet_num_first_gen_samples=10,\n",
        "      no_cuda=False,\n",
        "      random_seed=42,\n",
        "      logging_steps=50,\n",
        "      checkpoint=\"FacebookAI/roberta-large\",\n",
        "      dataset=\"yelp_review_full\"\n",
        "      ):\n",
        "\n",
        "    # MLM\n",
        "    self.max_seq_len = max_seq_len\n",
        "    self.train_batch_size = train_batch_size\n",
        "    self.eval_batch_size = eval_batch_size\n",
        "    self.mlm_batch_size = mlm_batch_size\n",
        "    self.gradient_accumulation_steps = gradient_accumulation_steps\n",
        "    self.num_train_steps = num_train_steps\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weight_decay = weight_decay\n",
        "    self.adam_epsilon = adam_epsilon\n",
        "    self.max_grad_norm = max_grad_norm\n",
        "\n",
        "    # Sequence classifier\n",
        "    self.cls_max_seq_len = cls_max_seq_len\n",
        "    self.cls_train_batch_size = cls_train_batch_size\n",
        "    self.cls_eval_batch_size = cls_eval_batch_size\n",
        "    self.cls_gradient_accumulation_steps = cls_gradient_accumulation_steps\n",
        "    self.cls_num_train_steps = cls_num_train_steps\n",
        "    self.cls_learning_rate = cls_learning_rate\n",
        "    self.cls_weight_decay = cls_weight_decay\n",
        "    self.cls_adam_epsilon = cls_adam_epsilon\n",
        "    self.cls_max_grad_norm = cls_max_grad_norm\n",
        "\n",
        "    # PET\n",
        "    self.pet_cls_train_batch_size = pet_cls_train_batch_size\n",
        "    self.pet_cls_eval_batch_size = pet_cls_eval_batch_size\n",
        "    self.pet_models_per_pattern = pet_models_per_pattern\n",
        "    self.pet_alpha = pet_alpha\n",
        "    self.pet_temperature = pet_temperature\n",
        "\n",
        "    # iPET\n",
        "    self.ipet_num_generations = ipet_num_generations\n",
        "    self.ipet_models_fraction = ipet_models_fraction\n",
        "    self.ipet_train_scale_factor = ipet_train_scale_factor\n",
        "    self.ipet_num_first_gen_samples = ipet_num_first_gen_samples\n",
        "\n",
        "    # Other\n",
        "    self.num_unlabeled_sampes_per_label = num_unlabeled_sampes_per_label\n",
        "    self.checkpoint = checkpoint\n",
        "    self.dataset = dataset\n",
        "    self.random_seed = random_seed\n",
        "    self.no_cuda = no_cuda\n",
        "    self.logging_steps = logging_steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w-mP5C0zmBQ"
      },
      "outputs": [],
      "source": [
        "# Shared utility function\n",
        "def compute_accuracy(\n",
        "    preds,\n",
        "    labels\n",
        "    ):\n",
        "\n",
        "  \"\"\" Helper for computing evaluation accuracy \"\"\"\n",
        "\n",
        "  return (torch.argmax(preds, -1) == labels).float().mean().item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLW_KYrEhI_"
      },
      "outputs": [],
      "source": [
        "# Define model trainers and evaluators\n",
        "\n",
        "class SingleModelTrainer(object):\n",
        "\n",
        "  \"\"\" Trains and evaluates a single PET model. \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      config,\n",
        "      tokenizer,\n",
        "      verbalizer,\n",
        "      pattern_id,\n",
        "      model_id,\n",
        "      model_path=None,\n",
        "      train_pet_classifier=False,\n",
        "      train_sup_classifier=False\n",
        "      ):\n",
        "\n",
        "    self.config = config\n",
        "\n",
        "    # Instantiate tokenizer and verbalizer\n",
        "    self.tokenizer = tokenizer\n",
        "    self.verbalizer = verbalizer\n",
        "\n",
        "    self.train_pet_classifier = train_pet_classifier\n",
        "    self.train_sup_classifier = train_sup_classifier\n",
        "\n",
        "    # Initialize model to fine-tune\n",
        "    if not (self.train_pet_classifier or self.train_sup_classifier):\n",
        "      if model_path is None:\n",
        "        self.model = AutoModelForPreTraining.from_pretrained(\n",
        "            self.config.checkpoint)\n",
        "      else:\n",
        "        self.model = AutoModelForPreTraining.from_pretrained(model_path)\n",
        "    else:\n",
        "      self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "          self.config.checkpoint,\n",
        "          num_labels=len(self.verbalizer.label_dict.keys()))\n",
        "\n",
        "    # Check if GPU can be used\n",
        "    self.device = \"cuda\" if torch.cuda.is_available() and not self.config.no_cuda else \"cpu\"\n",
        "    if self.device == \"cuda\":\n",
        "      print(\"CUDA is available, using GPU for model training and evaluation.\")\n",
        "    else:\n",
        "      print(\"CUDA is unavailable, using CPU for model training and evaluation.\")\n",
        "    self.model.to(self.device)\n",
        "\n",
        "\n",
        "    # Decide on hyperparameters to use based on type of trained model\n",
        "    if self.train_pet_classifier or self.train_sup_classifier:\n",
        "      self.max_seq_len = self.config.cls_max_seq_len\n",
        "      self.gradient_accumulation_steps = self.config.cls_gradient_accumulation_steps\n",
        "      self.num_train_steps = self.config.cls_num_train_steps\n",
        "      self.learning_rate = self.config.cls_learning_rate\n",
        "      self.weight_decay = self.config.cls_weight_decay\n",
        "      self.adam_epsilon = self.config.cls_adam_epsilon\n",
        "      self.max_grad_norm = self.config.cls_max_grad_norm\n",
        "      if self.train_pet_classifier:\n",
        "        self.train_batch_size = self.config.pet_cls_train_batch_size\n",
        "        self.eval_batch_size = self.config.pet_cls_eval_batch_size\n",
        "      else:\n",
        "        self.train_batch_size = self.config.cls_train_batch_size\n",
        "        self.eval_batch_size = self.config.cls_eval_batch_size\n",
        "\n",
        "    else:\n",
        "      self.max_seq_len = self.config.max_seq_len\n",
        "      self.gradient_accumulation_steps = self.config.gradient_accumulation_steps\n",
        "      self.num_train_steps = self.config.num_train_steps\n",
        "      self.learning_rate = self.config.learning_rate\n",
        "      self.weight_decay = self.config.weight_decay\n",
        "      self.adam_epsilon = self.config.adam_epsilon\n",
        "      self.max_grad_norm = self.config.max_grad_norm\n",
        "      self.train_batch_size = self.config.train_batch_size\n",
        "      self.eval_batch_size = self.config.eval_batch_size\n",
        "\n",
        "    # Define model name\n",
        "    if self.train_pet_classifier:\n",
        "      self.model_name = \"PET_CLASSIFIER\"\n",
        "    elif self.train_sup_classifier:\n",
        "      self.model_name = \"SUPERVISED_CLASSIFIER\"\n",
        "    else:\n",
        "      if pattern_id is not None and model_id is not None:\n",
        "        self.model_name = \"PET_LM_pattern_{:d}_model_{:d}\".format(\n",
        "            pattern_id, model_id)\n",
        "      else:\n",
        "        self.model_name = \"PET_LM\"\n",
        "\n",
        "\n",
        "  def train(\n",
        "      self,\n",
        "      labeled_dataloader,\n",
        "      unlabeled_dataloader,\n",
        "      use_mlm_training=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Trains the specified model. \"\"\"\n",
        "\n",
        "    # Compute number of training epochs from total training steps\n",
        "    num_train_epochs = int(np.round(self.num_train_steps // max(\n",
        "        1, (len(labeled_dataloader)) // self.gradient_accumulation_steps)))\n",
        "\n",
        "    # !! NOTE: This code below is *partially* copied from the paper's codebase,\n",
        "    # since it's boilerplate model training code !!\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in self.model.named_parameters() if not any(\n",
        "            nd in n for nd in no_decay)],\n",
        "          'weight_decay': self.config.weight_decay},\n",
        "        {'params': [p for n, p in self.model.named_parameters() if any(\n",
        "            nd in n for nd in no_decay)],\n",
        "          'weight_decay': 0.0}]\n",
        "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters,\n",
        "                                  lr=self.learning_rate,\n",
        "                                  eps=self.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=self.num_train_steps)\n",
        "\n",
        "    # Initialize traning variables\n",
        "    step, global_step = 0, 0\n",
        "    tr_loss, last_reported_loss = 0.0, 0.0\n",
        "    mean_training_loss = 0.0\n",
        "    # Reset model gradient\n",
        "    self.model.zero_grad()\n",
        "\n",
        "    # Enable iteration over unlabeled data for auxiliary training\n",
        "    # Unlabeled dataloader has to be None for classifier training\n",
        "    if self.train_pet_classifier or self.train_sup_classifier:\n",
        "      assert unlabeled_dataloader is None, \"Unlabeled data is not compatible with classifier training!\"\n",
        "    if unlabeled_dataloader is None:\n",
        "      assert use_mlm_training is False, \"Can't execute auxiliary MLM training if no unlabeled data is provided!\"\n",
        "    else:\n",
        "      unlabeled_iter = unlabeled_dataloader.__iter__()\n",
        "\n",
        "    print(\"Starting training model: {:s}\".format(self.model_name))\n",
        "\n",
        "    # Report hyper-parameters used during training\n",
        "    print('Hyperparameters:')\n",
        "    print(\"max_seq_len: {}\".format(self.config.cls_max_seq_len))\n",
        "    print(\"gradient_accumulation_steps: {}\".format(\n",
        "        self.config.cls_gradient_accumulation_steps))\n",
        "    print(\"num_train_steps: {}\".format(self.config.cls_num_train_steps))\n",
        "    print(\"learning_rate: {}\".format(self.config.cls_learning_rate))\n",
        "    print(\"weight_decay: {}\".format(self.config.cls_weight_decay))\n",
        "    print(\"adam_epsilon: {}\".format(self.config.cls_adam_epsilon))\n",
        "    print(\"max_grad_norm: {}\".format(self.config.cls_max_grad_norm))\n",
        "    print(\"train_batch_size: {}\".format(self.config.pet_cls_train_batch_size))\n",
        "    print(\"eval_batch_size: {}\".format(self.config.pet_cls_eval_batch_size))\n",
        "\n",
        "    train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
        "    for epoch_id, _ in enumerate(train_iterator):\n",
        "      epoch_iterator = tqdm(labeled_dataloader, desc=\"Iteration\")\n",
        "      for batch_id, batch in enumerate(epoch_iterator):\n",
        "\n",
        "        # Sanity check of batch contents\n",
        "        # if epoch_id == 0 and batch_id == 0:\n",
        "        #   print(\"\\nCONTENTS OF FIRST TRAINING BATCH:\")\n",
        "        #   for k, v in batch.items():\n",
        "        #     print(\"\\t {}: {}\".format(k, v))\n",
        "        #     if type(v) == torch.Tensor:\n",
        "        #       print(\"Size {}: {}\".format(k, v.size()))\n",
        "\n",
        "        # Training mode\n",
        "        self.model.train()\n",
        "        unlabeled_batch = None\n",
        "        # Prepare labeled inpts\n",
        "        labeled_batch_inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"],\n",
        "            \"attention_mask\": batch[\"attention_mask\"]\n",
        "            }\n",
        "        if self.train_sup_classifier:\n",
        "          labeled_batch_inputs[\"labels\"] = batch[\"label\"]\n",
        "        labeled_batch_inputs = {k: t.to(self.device) for k, t in batch.items()}\n",
        "        outputs = self.model(**labeled_batch_inputs)\n",
        "        model_logits = outputs[0]\n",
        "\n",
        "        # Compute model loss\n",
        "        if not (self.train_pet_classifier or self.train_sup_classifier):\n",
        "          # Compute PET training loss\n",
        "          cls_logits = self._get_logits_at_pet_labels(\n",
        "              batch[\"input_ids\"], model_logits)\n",
        "          pet_labels = batch[\"labels_array\"].float()\n",
        "          loss = torch.nn.CrossEntropyLoss()(\n",
        "              cls_logits.view(-1), pet_labels.view(-1))\n",
        "        else:\n",
        "          if self.train_pet_classifier:\n",
        "            # Compute PET classifier loss\n",
        "            model_probabilities = torch.nn.functional.log_softmax(\n",
        "                model_logits / self.config.pet_temperature, dim=-1)\n",
        "            loss = torch.nn.functional.kl_div(\n",
        "                model_probabilities, batch[\"labels\"], reduction=\"sum\") * (\n",
        "                    self.config.pet_temperature ** 2) / model_probabilities.shape[0]\n",
        "          else:\n",
        "            # Obtain supervised classifier loss\n",
        "            loss = outputs.loss\n",
        "\n",
        "        if use_mlm_training:\n",
        "          # Prepare a batch of unlabeled data\n",
        "          while unlabeled_batch is None:\n",
        "            try:\n",
        "                unlabeled_batch = unlabeled_iter.__next__()\n",
        "            except StopIteration:\n",
        "                unlabeled_iter = unlabeled_dataloader.__iter__()\n",
        "            mlm_input_ids = unlabeled_batch[\"input_ids\"]\n",
        "            (unlabeled_batch[\"input_ids\"],\n",
        "             unlabeled_batch[\"mlm_labels\"]) = self._prepare_mlm_data(\n",
        "                 mlm_input_ids)\n",
        "\n",
        "          # Compute auxiliary loss\n",
        "          unlabeled_batch_inputs = {\n",
        "              \"input_ids\": unlabeled_batch[\"input_ids\"],\n",
        "              \"attention_mask\": batch[\"attention_mask\"]\n",
        "              }\n",
        "          unlabeled_batch_inputs[\"labels\"] = unlabeled_batch[\"mlm_labels\"]\n",
        "          unlabeled_batch_inputs = {\n",
        "                k: t.to(self.device) for k, t in unlabeled_batch_inputs.items()}\n",
        "\n",
        "          lm_loss = self.model(**unlabeled_batch_inputs)[0]\n",
        "          # Combine losses\n",
        "          loss = self.config.pet_alpha * loss + (\n",
        "              1 - self.config.pet_alpha) * lm_loss\n",
        "\n",
        "        if self.gradient_accumulation_steps > 1:\n",
        "          loss = loss / self.gradient_accumulation_steps\n",
        "\n",
        "        # Track training loss\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        # Get gradients\n",
        "        loss.backward()\n",
        "        step += 1\n",
        "\n",
        "        # Update model after N gradient accumulation steps\n",
        "        if (step + 1) % self.gradient_accumulation_steps == 0:\n",
        "          # Backpropagate, reglarize, optimize\n",
        "          torch.nn.utils.clip_grad_norm_(\n",
        "              self.model.parameters(), self.max_grad_norm)\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          # Reset gradient\n",
        "          self.model.zero_grad()\n",
        "          global_step += 1\n",
        "\n",
        "          if (self.config.logging_steps > 0 and\n",
        "              global_step % self.config.logging_steps == 0):\n",
        "            curr_mean_loss = (\n",
        "                tr_loss - last_reported_loss) / self.config.logging_steps\n",
        "            curr_learning_rate = scheduler.get_lr()[0]\n",
        "            past_reported_loss = tr_loss\n",
        "            print(\"\\tGlobal step: {:d} | LR: {:.4f} | Avg. loss: {:.3f}\".format(\n",
        "                global_step, curr_learning_rate, self.config.logging_steps,\n",
        "                curr_mean_loss))\n",
        "\n",
        "        # Stop iteration after maximum number of training steps\n",
        "        if self.num_train_steps < global_step:\n",
        "          epoch_iterator.close()\n",
        "          break\n",
        "\n",
        "      # Stop iteration after maximum number of training steps\n",
        "      if 0 < self.config.num_train_steps < global_step:\n",
        "        train_iterator.close()\n",
        "        mean_training_loss = tr_loss / global_step\n",
        "        print(\"== Finished training model: {:s} ==\".format(self.model_name))\n",
        "        print(\"\\tMean training loss: {:.3f}\".format(mean_training_loss))\n",
        "        break\n",
        "\n",
        "    # Report mean training loss for weighted logit combination\n",
        "    return global_step, mean_training_loss\n",
        "\n",
        "\n",
        "  def eval(\n",
        "      self,\n",
        "      eval_dataloader,\n",
        "      is_unlabeled,\n",
        "      return_logits,\n",
        "      pet_samples=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Evaluates the specified model / annotates data with logits. \"\"\"\n",
        "\n",
        "    # !! NOTE: This code below is *partially* copied from the paper's codebase,\n",
        "    # since it's boilerplate model evaluation code !!\n",
        "\n",
        "    # Collect for evaluation\n",
        "    all_logits = list()\n",
        "    all_labels = list()\n",
        "\n",
        "    eval_step = 0\n",
        "    eval_acc = 0.\n",
        "\n",
        "    # Iterate over evaluation data\n",
        "    for batch_id, batch in enumerate(\n",
        "        tqdm(eval_dataloader, desc=\"Evaluating / Annotating\")):\n",
        "\n",
        "      # # TODO: DEBUGGING\n",
        "      # if batch_id == 20:\n",
        "      #   break\n",
        "\n",
        "      # Sanity check of batch contents\n",
        "      # if batch_id == 0:\n",
        "      #   print(\"\\nCONTENTS OF FIRST EVALUATION BATCH:\")\n",
        "      #   for k, v in batch.items():\n",
        "      #     print(\"\\t {}: {}\".format(k, v))\n",
        "      #     if type(v) == torch.Tensor:\n",
        "      #       print(\"Size {}: {}\".format(k, v.size()))\n",
        "\n",
        "      # Evaluation mode\n",
        "      self.model.eval()\n",
        "\n",
        "      # Iterate over evaluation data\n",
        "      with torch.no_grad():\n",
        "        # Prepare inputs\n",
        "        batch_inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"],\n",
        "            \"attention_mask\": batch[\"attention_mask\"]\n",
        "            }\n",
        "        #if self.train_pet_classifier or self.train_sup_classifier:\n",
        "        labels = batch[\"label\"].to(self.device)\n",
        "\n",
        "        # else:\n",
        "        #   labels = batch[\"labels_array\"]\n",
        "\n",
        "        batch_inputs = {k: t.to(self.device) for k, t in batch_inputs.items()}\n",
        "        # Get outputs\n",
        "        outputs = self.model(**batch_inputs)\n",
        "        # Get model logits\n",
        "        logits = outputs[0]\n",
        "        if pet_samples:\n",
        "          logits = self._get_logits_at_pet_labels(\n",
        "              batch_inputs[\"input_ids\"], logits)\n",
        "\n",
        "      # Compute model accuracy (unless used for annotation of unlabeled data)\n",
        "      if not is_unlabeled:\n",
        "        eval_acc += compute_accuracy(logits, labels)\n",
        "\n",
        "      if return_logits:\n",
        "        # Collect logits for the entire evaluation set\n",
        "        all_logits.append(logits.detach().cpu().numpy())\n",
        "        all_labels.append(labels.detach().cpu().numpy())\n",
        "      eval_step += 1\n",
        "\n",
        "    if return_logits:\n",
        "      # Concatenate logits / labels\n",
        "      all_logits = np.concatenate(all_logits, axis=0)\n",
        "      all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    # Report model accuracy on the evaluation set\n",
        "    print(\"== Finished evaluating model: {:s} ==\".format(self.model_name))\n",
        "    mean_eval_acc = 0.\n",
        "    if not is_unlabeled:\n",
        "      mean_eval_acc = eval_acc / eval_step\n",
        "      print(\"\\tMean evaluation acc: {:.3f}\".format(mean_eval_acc))\n",
        "\n",
        "    return {\n",
        "        'logits': all_logits,\n",
        "        'labels': all_labels,\n",
        "        'eval_acc': mean_eval_acc\n",
        "        }\n",
        "\n",
        "\n",
        "  def _get_logits_at_pet_labels(\n",
        "      self,\n",
        "      input_ids,\n",
        "      model_logits\n",
        "      ):\n",
        "\n",
        "    \"\"\" Gathers model logits corresponding to verbalizations of task labels. \"\"\"\n",
        "\n",
        "    # Assumes input of shape [batch_size, time_steps, vocab_size]\n",
        "    # Gather model predictions at the masked positions -> [batch x vocab_size]\n",
        "    logits_at_mask = model_logits[input_ids == self.tokenizer.mask_token_id]\n",
        "    logits_at_labels_list = list()\n",
        "    for batch_item_logits in logits_at_mask:\n",
        "      logits_at_labels_list.append(\n",
        "          batch_item_logits[self.verbalizer.label_token_ids])\n",
        "\n",
        "    # Stack gathered logits to be same shape as label -> [batch x num_labels]\n",
        "    return torch.stack(logits_at_labels_list, dim=0)\n",
        "\n",
        "\n",
        "  def _prepare_mlm_data(\n",
        "      self,\n",
        "      input_ids,\n",
        "      ):\n",
        "\n",
        "    \"\"\" Transforms unlabeled data for use with the MLM training objective;\n",
        "    Transformations are done per sample, not batch. \"\"\"\n",
        "\n",
        "    # Create a label tensor for the MLM objective\n",
        "    mlm_labels = torch.ones_like(input_ids) * -100\n",
        "\n",
        "    # Select positions to be transformed\n",
        "    input_shape = torch.tensor(input_ids.shape)\n",
        "\n",
        "    # 15% of tokens per line are modified\n",
        "    num_tokens_per_line = input_shape[1]\n",
        "    num_samples = int(np.round(num_tokens_per_line * 0.15))\n",
        "    for b in range(input_shape[0]):\n",
        "      # Exclude masked positions from transformations\n",
        "      valid_positions = list()\n",
        "      for t in range(num_tokens_per_line):\n",
        "          if input_ids[b, t] != self.tokenizer.mask_token_id:\n",
        "            valid_positions.append(t)\n",
        "\n",
        "      # Sample positions to be transformed\n",
        "      sampled_token_positions = random.sample(valid_positions, num_samples)\n",
        "\n",
        "      # Modify sampled token\n",
        "      for t in sampled_token_positions:\n",
        "        # Designate as a target within the label\n",
        "        mlm_labels[b, t] = input_ids[b, t]\n",
        "\n",
        "        # Decide on transformation\n",
        "        flip = random.uniform(0., 1.)\n",
        "        if flip < 0.8:\n",
        "          # Replace by a MASK token in 80% of cases\n",
        "          input_ids[b, t] = self.tokenizer.mask_token_id\n",
        "        else:\n",
        "          if flip < 0.9:\n",
        "            # Replace with a random token in 10% of cases\n",
        "            input_ids[b, t] = random.randint(0, len(self.tokenizer) - 1)\n",
        "          else:\n",
        "            # Leave unchanged in 10% of cases\n",
        "            continue\n",
        "\n",
        "    return input_ids, mlm_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_mmV4Ezzb8p"
      },
      "outputs": [],
      "source": [
        "class MultiModelTrainer(object):\n",
        "\n",
        "  \"\"\" Trains and evaluates a PET ensemble (+ optional classifier), and unsupervised baselines. \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      config,\n",
        "      data_initializer,\n",
        "      data_processor,\n",
        "      tokenizer,\n",
        "      verbalizer,\n",
        "      num_training_samples,\n",
        "      eval_dataloaders,\n",
        "      use_mlm_training,\n",
        "      weighting_strategy=\"mean\"\n",
        "      ):\n",
        "\n",
        "    self.root_dir = \"/content/\"\n",
        "    self.config = config\n",
        "\n",
        "    self.data_initializer = data_initializer\n",
        "    self.data_processor = data_processor\n",
        "    self.tokenizer = tokenizer\n",
        "    self.verbalizer = verbalizer\n",
        "\n",
        "    self.use_mlm_training = use_mlm_training\n",
        "    self.num_training_samples = num_training_samples\n",
        "\n",
        "    # Prepare training data for all PET patterns\n",
        "    self.training_data_per_label = self.data_processor.train_data_per_label\n",
        "\n",
        "    # Sample PET and unlabeled data to be used across ALL models in the ensemble\n",
        "    self.num_training_samples = num_training_samples\n",
        "    self.num_samples_per_label = self.num_training_samples // self.data_processor.num_labels\n",
        "    self.eval_dataloaders = eval_dataloaders\n",
        "    # Sample intial data\n",
        "    self.pet_train_samples, self.unlabeled_train_samples = self.data_processor.sample_data(\n",
        "        self.training_data_per_label, self.num_samples_per_label, is_eval=False)\n",
        "\n",
        "    # Keep track of individual models\n",
        "    self.model_records = dict()\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def _save_logits(\n",
        "      logits_dict,\n",
        "      out_path\n",
        "      ):\n",
        "\n",
        "    \"\"\" Saves logits and labels of the soft-labeled data to disc. \"\"\"\n",
        "\n",
        "    with open(out_path, 'wb') as pf:\n",
        "      pickle.dump(logits_dict, pf, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print(\"Saved logits to {:s}\".format(out_path))\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def _load_logits(\n",
        "      logits_path\n",
        "      ):\n",
        "\n",
        "    \"\"\" Loads logits and labels of soft-labeled data from disc. \"\"\"\n",
        "\n",
        "    print(\"Loading logits from {:s}\".format(logits_path))\n",
        "    with open(logits_path, 'rb') as pf:\n",
        "      return pickle.load(pf)\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def _save_model(\n",
        "      model,\n",
        "      out_path\n",
        "      ):\n",
        "\n",
        "    \"\"\" Saves a model checkpoint to disk. \"\"\"\n",
        "\n",
        "    # Save model\n",
        "    model = model.module if hasattr(model, 'module') else model\n",
        "    model.save_pretrained(out_path)\n",
        "\n",
        "\n",
        "  def _merge_logits(\n",
        "      self,\n",
        "      weighting_strategy,\n",
        "      model_logits=None,\n",
        "      for_classifier=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Merges logits for classifier training or PET ensamble evaluation. \"\"\"\n",
        "\n",
        "    merged_logits = None\n",
        "\n",
        "    if not for_classifier:\n",
        "        model_logits = self.model_records if model_logits is None else model_logits\n",
        "        # Merge logits for the PET ensemble\n",
        "        if weighting_strategy == \"weighted\":\n",
        "          logits = [\n",
        "              model_logits[k][\"logits\"] *\n",
        "              model_logits[k][\"model_init_train_acc\"] for k in model_logits.keys()]\n",
        "        else:\n",
        "          logits = [model_logits[k][\"logits\"] for k in model_logits.keys()]\n",
        "        merged_logits = torch.tensor(np.mean(logits, axis=0))\n",
        "        labels = model_logits[list(model_logits.keys())[0]][\"eval_labels\"]\n",
        "\n",
        "    else:\n",
        "      print(\"Merging unlabelled logits ...\")\n",
        "      # Logits are stored on the drive; load and keep a their running sum\n",
        "      numerator = 0\n",
        "\n",
        "      for pattern_id in self.verbalizer.pattern_dict.keys():\n",
        "        for model_id in range(self.config.pet_models_per_pattern):\n",
        "          # Specify logits path\n",
        "          pwd = os.path.join(self.root_dir, 'pet_model_{}_pattern_{}/'.format(\n",
        "              model_id, pattern_id))\n",
        "          logits_path = os.path.join(pwd, \"unlabeled_logits.pickle\")\n",
        "          try:\n",
        "            unlabeled_logits_and_labels = self._load_logits(logits_path)\n",
        "          except FileNotFoundError:\n",
        "            continue\n",
        "          model_weight = 1.0\n",
        "          if weighting_strategy != \"uniform\":\n",
        "            model_weight = unlabeled_logits_and_labels[\"model_init_train_acc\"]\n",
        "          if merged_logits is None:\n",
        "            merged_logits = unlabeled_logits_and_labels[\"logits\"] * model_weight\n",
        "          else:\n",
        "            merged_logits += (unlabeled_logits_and_labels[\"logits\"] *\n",
        "                              model_weight)\n",
        "          numerator += 1\n",
        "      labels = unlabeled_logits_and_labels[\"labels\"]\n",
        "\n",
        "      # Compute mean\n",
        "      merged_logits /= numerator\n",
        "      merged_logits = torch.tensor(merged_logits)\n",
        "\n",
        "    # Apply softmax\n",
        "    merged_softmax = torch.nn.functional.log_softmax(\n",
        "        merged_logits / self.config.pet_temperature, dim=-1)\n",
        "\n",
        "    return merged_softmax, labels\n",
        "\n",
        "\n",
        "  def train_pet_ensemble(\n",
        "      self,\n",
        "      weighting_strategy=\"uniform\",\n",
        "      get_unlabeled_logits=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Trains a PET model ensemble. \"\"\"\n",
        "\n",
        "    # Train N models for each pattern and annotate unlabeled data (for PET)\n",
        "    out = dict()\n",
        "    pattern_eval_weights = dict()\n",
        "    dataloaders = dict()\n",
        "\n",
        "    for p_id, pattern_id in enumerate(self.verbalizer.pattern_dict.keys()):\n",
        "      out[pattern_id] = dict()\n",
        "      pattern_eval_weights[pattern_id] = None\n",
        "      dataloaders[pattern_id] = None\n",
        "\n",
        "      for model_id in range(self.config.pet_models_per_pattern):\n",
        "        # Define model key\n",
        "        model_key = \"pet_pattern_{:d}_model_{:d}/\".format(pattern_id, model_id)\n",
        "        # Make directory to save everything for this ensemble to\n",
        "        pwd = os.path.join(self.root_dir, \"num_samples_{:d}_{:s}/\".format(\n",
        "            self.num_training_samples, model_key))\n",
        "        if not os.path.isdir(pwd):\n",
        "          os.mkdir(pwd)\n",
        "\n",
        "        # Initialize model\n",
        "        model_trainer = SingleModelTrainer(\n",
        "            self.config, self.tokenizer, self.verbalizer, pattern_id, model_id)\n",
        "\n",
        "        # Generate training data for each PET pattern\n",
        "        if dataloaders[pattern_id] is None:\n",
        "          (train_pet_dataloader, train_unlabeled_dataloader,\n",
        "          sequential_unlabeled_dataloader) = self.data_processor.get_dataloader(\n",
        "              pattern_id, self.pet_train_samples, self.unlabeled_train_samples,\n",
        "              self.config.train_batch_size, self.config.eval_batch_size,\n",
        "              use_mlm_training=self.use_mlm_training, is_eval=False,\n",
        "              get_sequential_unlabeled_data=True, no_verbalization=False)\n",
        "          dataloaders[pattern_id] = [\n",
        "              train_pet_dataloader, train_unlabeled_dataloader,\n",
        "              sequential_unlabeled_dataloader]\n",
        "        else:\n",
        "          (train_pet_dataloader, train_unlabeled_dataloader,\n",
        "           sequential_unlabeled_dataloader) = dataloaders[pattern_id]\n",
        "\n",
        "        # Obtain \"pre-training\" accuracy to be used for model weighting\n",
        "        if pattern_eval_weights[pattern_id] is None:\n",
        "          if weighting_strategy == \"weighted\":\n",
        "            logits_and_labels = model_trainer.eval(\n",
        "                train_pet_dataloader, is_unlabeled=False,\n",
        "                return_logits=False, pet_samples=True)\n",
        "            pattern_eval_weights[pattern_id] = logits_and_labels[\"eval_acc\"]\n",
        "        else:\n",
        "          pattern_eval_weights[pattern_id] = 1.\n",
        "\n",
        "        # Train a single model\n",
        "        if self.num_training_samples > 0:\n",
        "          num_raining_steps, train_loss = model_trainer.train(\n",
        "              train_pet_dataloader, train_unlabeled_dataloader,\n",
        "              self.use_mlm_training)\n",
        "\n",
        "        # Evaluate a single model (on the eval set)\n",
        "        logits_and_labels = model_trainer.eval(\n",
        "            self.eval_dataloaders[pattern_id], is_unlabeled=False,\n",
        "            return_logits=True, pet_samples=True)\n",
        "        # Update model records (used in model ensembling)\n",
        "        self.model_records[model_key] = dict()\n",
        "        self.model_records[model_key][\n",
        "            \"model_init_train_acc\"] = pattern_eval_weights[pattern_id]\n",
        "        self.model_records[model_key][\n",
        "            \"logits\"] = logits_and_labels[\"logits\"]\n",
        "        self.model_records[model_key][\n",
        "            \"eval_labels\"] = logits_and_labels[\"labels\"]\n",
        "\n",
        "        out[pattern_id][model_id] = logits_and_labels[\"eval_acc\"]\n",
        "\n",
        "        if get_unlabeled_logits:\n",
        "          # Obtain logits for unlabeled data\n",
        "          print(\"Labeling unlabeled data!\")\n",
        "          unlabeled_logits_and_labels = model_trainer.eval(\n",
        "              sequential_unlabeled_dataloader, is_unlabeled=True,\n",
        "              return_logits=True, pet_samples=True)\n",
        "          unlabeled_logits_and_labels[\n",
        "              \"model_init_train_acc\"] = pattern_eval_weights[pattern_id]\n",
        "          # Save logits to disc\n",
        "          print(\"Saving labeled unlabeled data!\")\n",
        "          out_dir = os.path.join(\n",
        "              self.root_dir,\n",
        "              \"pet_model_{}_pattern_{}/\".format(model_id, pattern_id))\n",
        "          if not os.path.isdir(out_dir):\n",
        "            os.mkdir(out_dir)\n",
        "          out_path = os.path.join(out_dir, 'unlabeled_logits.pickle')\n",
        "          self._save_logits(unlabeled_logits_and_labels, out_path)\n",
        "\n",
        "    print('--- Finished training the PET ensemble! --- ')\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "  def _get_next_ipet_data(\n",
        "      self,\n",
        "      merged_logits,\n",
        "      num_pet_samples_per_label,\n",
        "      already_sampled,\n",
        "      zero_shot=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Generates iPET data for training the next model generation. \"\"\"\n",
        "\n",
        "    # Draw samples with highest annotation probabilities to be used in\n",
        "    # the training of the next iPET generation\n",
        "\n",
        "    new_samples = dict()\n",
        "    new_unlabeled_samples = dict()\n",
        "    # Map sample ids to samples for easier retrieval\n",
        "    candidate_id = 0\n",
        "    sample_labels = sorted(list(self.unlabeled_train_samples.keys()))\n",
        "\n",
        "    for label in sample_labels:\n",
        "      candidate_map = dict()\n",
        "\n",
        "      # # TODO: DEBUGGING\n",
        "      # if candidate_id == merged_logits.size()[0]:\n",
        "      #   break\n",
        "\n",
        "      for sample in self.unlabeled_train_samples[label]:\n",
        "        if candidate_id not in already_sampled:\n",
        "          candidate_map[candidate_id] = sample\n",
        "        candidate_id += 1\n",
        "\n",
        "        # # TODO: DEBUGGING\n",
        "        # if candidate_id == merged_logits.size()[0]:\n",
        "        #   break\n",
        "\n",
        "      all_candidate_ids = list(candidate_map.keys())\n",
        "\n",
        "      # Get probability distributions and sample\n",
        "      label_candidates, probabilities = list(), list()\n",
        "      new_samples[label] = list()\n",
        "      new_unlabeled_samples[label] = list()\n",
        "      # if zero-shot, find 100 samples with the highest label probability,\n",
        "      # even if the current label is not the top label\n",
        "      if zero_shot:\n",
        "        label_candidates_and_probs = [(\n",
        "            c_id, merged_logits[c_id][label].item()) for c_id in\n",
        "                                      all_candidate_ids]\n",
        "        sorted_label_candidates_and_probs = sorted(\n",
        "            label_candidates_and_probs, reverse=True, key=lambda x: x[1])\n",
        "        # Pick the top 100\n",
        "        for c_id, prob in sorted_label_candidates_and_probs[:100]:\n",
        "            label_candidates.append(c_id)\n",
        "            probabilities.append(prob)\n",
        "\n",
        "      else:\n",
        "        # Select samples with highest probability assigned to the current label\n",
        "        for c_id in all_candidate_ids:\n",
        "          if torch.argmax(merged_logits[c_id]) == label:\n",
        "            label_candidates.append(c_id)\n",
        "            probabilities.append(merged_logits[c_id][label].item())\n",
        "\n",
        "      # Normalize label probabilities for weighted sampling\n",
        "      normalized_probabilities = np.exp(probabilities) / np.sum(\n",
        "          np.exp(probabilities), axis=0).tolist()\n",
        "      sampled_candidate_ids = np.random.choice(\n",
        "          label_candidates, size=num_pet_samples_per_label,\n",
        "          replace=False, p=normalized_probabilities).tolist()\n",
        "      already_sampled += sampled_candidate_ids\n",
        "\n",
        "      for sc_id in candidate_map.keys():\n",
        "        if sc_id in sampled_candidate_ids:\n",
        "          new_samples[label].append({\"text\": candidate_map[sc_id][\"text\"],\n",
        "                                     \"label\": label})\n",
        "        else:\n",
        "          new_unlabeled_samples[label].append(\n",
        "              {\"text\": candidate_map[sc_id][\"text\"],\n",
        "               \"label\": label})\n",
        "\n",
        "    return new_samples, new_unlabeled_samples, already_sampled\n",
        "\n",
        "\n",
        "  def train_ipet_ensemble(\n",
        "      self,\n",
        "      weighting_strategy=\"uniform\",\n",
        "      get_unlabeled_logits=False\n",
        "      ):\n",
        "\n",
        "    \"\"\" Trains a iPET model ensemble. \"\"\"\n",
        "\n",
        "    # Avoid sampling the same datapoint for more than one label\n",
        "    already_sampled = list()\n",
        "    # Keep track of samples per label in the growing iPET training data\n",
        "    num_pet_samples_per_label = self.num_samples_per_label\n",
        "    # Compute number of models to be sampled per iPET generation\n",
        "    num_sampled_models = int(np.round(len(self.verbalizer.pattern_dict.keys()) *\n",
        "                                      self.config.pet_models_per_pattern *\n",
        "                                      self.config.ipet_models_fraction))\n",
        "    # Keep track of pattern accuracies on the training set\n",
        "    pattern_eval_weights = dict()\n",
        "\n",
        "    init_ipet_gen_for_loop = 0\n",
        "\n",
        "    # Specify initial iPET data\n",
        "    if self.num_training_samples == 0:\n",
        "      # -- ZERO-SHOT iPET --\n",
        "      # Sample annotator models\n",
        "      pattern_candidates = list(\n",
        "          self.verbalizer.pattern_dict.keys()) * self.config.pet_models_per_pattern\n",
        "      sampled_pattern_ids = random.sample(pattern_candidates, num_sampled_models)\n",
        "      pattern_ids = list(set(sampled_pattern_ids))\n",
        "      model_ids = [sampled_pattern_ids.count(pi) for pi in pattern_ids]\n",
        "      dataloaders = dict()\n",
        "\n",
        "      # Initialize zero-shot models (no training)\n",
        "      logits_from_sampled_models = dict()\n",
        "      for pattern_id in pattern_ids:\n",
        "        if pattern_id not in dataloaders.keys():\n",
        "          dataloaders[pattern_id] = None\n",
        "        for model_id in model_ids:\n",
        "          model_trainer = SingleModelTrainer(\n",
        "              self.config, self.tokenizer, self.verbalizer,\n",
        "              pattern_id=pattern_id, model_id=model_id)\n",
        "          model_key = \"ipet_gen_{:d}_pattern_{:d}_model_{:d}/\".format(0, pattern_id, model_id)\n",
        "          logits_from_sampled_models[model_key] = dict()\n",
        "\n",
        "          # Get unlabelled dataloader\n",
        "          if dataloaders[pattern_id] is None:\n",
        "            _, _, sequential_unlabeled_dataloader = self.data_processor.get_dataloader(\n",
        "                pattern_id, self.pet_train_samples, self.unlabeled_train_samples,\n",
        "                self.config.train_batch_size, self.config.eval_batch_size,\n",
        "                use_mlm_training=self.use_mlm_training, is_eval=False,\n",
        "                get_sequential_unlabeled_data=True, no_verbalization=False)\n",
        "            dataloaders[pattern_id] = sequential_unlabeled_dataloader\n",
        "          else:\n",
        "              sequential_unlabeled_dataloader = dataloaders[pattern_id]\n",
        "\n",
        "          # Annotate unlabeled data with each selected model\n",
        "          print(\"Labeling unlabeled data with zero-shot model {:s}!\".format(model_key))\n",
        "          unlabeled_logits_and_labels = model_trainer.eval(\n",
        "              sequential_unlabeled_dataloader,\n",
        "              is_unlabeled=True, return_logits=True, pet_samples=True)\n",
        "          logits_from_sampled_models[model_key][\n",
        "              \"logits\"] = unlabeled_logits_and_labels[\"logits\"]\n",
        "          logits_from_sampled_models[model_key][\n",
        "              \"model_init_train_acc\"] = 1.  # since this is zero-shot\n",
        "          logits_from_sampled_models[model_key][\n",
        "              \"eval_labels\"] = unlabeled_logits_and_labels[\"labels\"]\n",
        "\n",
        "      # Merge logits\n",
        "      merged_logits, _ = self._merge_logits(\n",
        "          weighting_strategy, model_logits=logits_from_sampled_models,\n",
        "          for_classifier=False)\n",
        "      # Sample 10 samples across all labels\n",
        "      ipet_train_samples, ipet_unlabeled_samples, already_sampled = self._get_next_ipet_data(\n",
        "          merged_logits, int(np.round(10 / self.data_processor.num_labels)),\n",
        "          already_sampled, zero_shot=True)\n",
        "      # Update number of pet samples in current training data\n",
        "      num_pet_samples_per_label = self.config.ipet_train_scale_factor * num_pet_samples_per_label\n",
        "      # Increment iPET generations counter, since the first one did not involve training\n",
        "      init_ipet_gen_for_loop = 1\n",
        "    else:\n",
        "      ipet_train_samples = self.pet_train_samples  # start from the PET train set\n",
        "      ipet_unlabeled_samples = self.unlabeled_train_samples\n",
        "\n",
        "    # -- MULTI-SHOT iPET --\n",
        "    # Iterate over the specified number of iPET generations\n",
        "    for gen_id in range(init_ipet_gen_for_loop, self.config.ipet_num_generations):\n",
        "      trained_model_paths = list()\n",
        "      model_pre_training_accuracies = dict()\n",
        "      dataloaders = dict()  # reset each generation due to changes in data\n",
        "\n",
        "      if gen_id < self.config.ipet_num_generations - 1:\n",
        "        # Only train annotator models to improve efficiency\n",
        "        # Sample annotator models\n",
        "        pattern_candidates = list(self.verbalizer.pattern_dict.keys()) * self.config.pet_models_per_pattern\n",
        "        sampled_pattern_ids = random.sample(\n",
        "            pattern_candidates, num_sampled_models)\n",
        "        pattern_ids = list(set(sampled_pattern_ids))\n",
        "        model_ids = [sampled_pattern_ids.count(pi) for pi in pattern_ids]\n",
        "      else:\n",
        "        pattern_ids = self.verbalizer.pattern_dict.keys()\n",
        "        model_ids = range(self.config.pet_models_per_pattern)\n",
        "\n",
        "      # Train N models for each pattern per iPET generation\n",
        "      for pattern_id in pattern_ids:\n",
        "        if pattern_id not in pattern_eval_weights.keys():\n",
        "          pattern_eval_weights[pattern_id] = None\n",
        "        if pattern_id not in dataloaders.keys():\n",
        "          dataloaders[pattern_id] = None\n",
        "\n",
        "        for model_id in model_ids:\n",
        "          # Create directories for model checkpoints and logits\n",
        "          model_key = \"ipet_gen_{:d}_pattern_{:d}_model_{:d}/\".format(\n",
        "              gen_id, pattern_id, model_id)\n",
        "          model_save_path = os.path.join(\n",
        "              self.root_dir, \"num_samples_{:d}_{:s}/\".format(\n",
        "                  self.num_training_samples, model_key))\n",
        "          if not os.path.isdir(model_save_path):\n",
        "            os.mkdir(model_save_path)\n",
        "          trained_model_paths.append((model_key, pattern_id, model_save_path))\n",
        "\n",
        "          # Initialize model\n",
        "          model_trainer = SingleModelTrainer(\n",
        "              self.config, self.tokenizer, self.verbalizer, pattern_id, model_id)\n",
        "\n",
        "          if dataloaders[pattern_id] is None:\n",
        "            (train_pet_dataloader, train_unlabeled_dataloader,\n",
        "             sequential_unlabeled_dataloader) = self.data_processor.get_dataloader(\n",
        "                 pattern_id, ipet_train_samples, ipet_unlabeled_samples,\n",
        "                 self.config.train_batch_size, self.config.eval_batch_size,\n",
        "                 use_mlm_training=self.use_mlm_training, is_eval=False,\n",
        "                 get_sequential_unlabeled_data=True, no_verbalization=False)\n",
        "            dataloaders[pattern_id] = [\n",
        "                train_pet_dataloader, train_unlabeled_dataloader,\n",
        "                sequential_unlabeled_dataloader]\n",
        "          else:\n",
        "             (train_pet_dataloader, train_unlabeled_dataloader,\n",
        "              sequential_unlabeled_dataloader) = dataloaders[pattern_id]\n",
        "\n",
        "          eval_dataloader = self.eval_dataloaders[pattern_id]\n",
        "\n",
        "          # Obtain \"pre-training\" accuracy to be used for model weighting\n",
        "          if pattern_eval_weights[pattern_id] is None:\n",
        "            if weighting_strategy == \"weighted\":\n",
        "              logits_and_labels = model_trainer.eval(\n",
        "                  train_pet_dataloader, is_unlabeled=False,\n",
        "                  return_logits=False, pet_samples=True)\n",
        "              pattern_eval_weights[pattern_id] = logits_and_labels[\"eval_acc\"]\n",
        "            else:\n",
        "              pattern_eval_weights[pattern_id] = 1.\n",
        "          model_pre_training_accuracies[model_key] = pattern_eval_weights[pattern_id]\n",
        "\n",
        "          # Train a single model\n",
        "          num_raining_steps, train_loss = model_trainer.train(\n",
        "              train_pet_dataloader, train_unlabeled_dataloader,\n",
        "              self.use_mlm_training)\n",
        "          # Save trained model\n",
        "          self._save_model(model_trainer.model, model_save_path)\n",
        "\n",
        "          # In final iteration, obtain logits for unlabeled data from all models\n",
        "          if gen_id == self.config.ipet_num_generations - 1:\n",
        "            if get_unlabeled_logits:\n",
        "              print(\"Labeling unlabeled data!\")\n",
        "              unlabeled_logits_and_labels = model_trainer.eval(\n",
        "                  sequential_unlabeled_dataloader, is_unlabeled=True,\n",
        "                  return_logits=True, pet_samples=True)\n",
        "              unlabeled_logits_and_labels[\n",
        "                  \"model_init_train_acc\"] = pattern_eval_weights[pattern_id]\n",
        "              # Save logits to disc\n",
        "              print(\"Saving labeled unlabeled data!\")\n",
        "              out_dir = os.path.join(\n",
        "                  self.root_dir, 'pet_model_{}_pattern_{}/'.format(\n",
        "                      model_id, pattern_id))\n",
        "              if not os.path.isdir(out_dir):\n",
        "                os.mkdir(out_dir)\n",
        "              out_path = os.path.join(out_dir, 'unlabeled_logits.pickle')\n",
        "              self._save_logits(unlabeled_logits_and_labels, out_path)\n",
        "\n",
        "            # Perform evaluation of all individual models\n",
        "            logits_and_labels = model_trainer.eval(\n",
        "                eval_dataloader, is_unlabeled=False,\n",
        "                return_logits=True, pet_samples=True)\n",
        "            # Update model records\n",
        "            self.model_records[\n",
        "                \"pattern_{:d}_model_{:d}\".format(pattern_id, model_id)] = dict()\n",
        "            self.model_records[\n",
        "                \"pattern_{:d}_model_{:d}\".format(pattern_id, model_id)][\n",
        "                    \"model_init_train_acc\"] = pattern_eval_weights[pattern_id]\n",
        "            self.model_records[\n",
        "                \"pattern_{:d}_model_{:d}\".format(pattern_id, model_id)][\n",
        "                    \"eval_acc\"] = logits_and_labels[\"eval_acc\"]\n",
        "            self.model_records[\n",
        "                \"pattern_{:d}_model_{:d}\".format(pattern_id, model_id)][\n",
        "                    \"logits\"] = logits_and_labels[\"logits\"]\n",
        "            self.model_records[\n",
        "                \"pattern_{:d}_model_{:d}\".format(pattern_id, model_id)][\n",
        "                    \"eval_labels\"] = logits_and_labels[\"labels\"]\n",
        "\n",
        "            print('--- Finished training the iPET ensemble! --- ')\n",
        "\n",
        "      if gen_id < self.config.ipet_num_generations - 1:\n",
        "\n",
        "        # Expand the iPET training set\n",
        "        logits_from_sampled_models = dict()\n",
        "        for model_key, pattern_id, model_path in trained_model_paths:\n",
        "          logits_from_sampled_models[model_key] = dict()\n",
        "          model_trainer = SingleModelTrainer(\n",
        "              self.config, self.tokenizer, self.verbalizer, None, None,\n",
        "              model_path=model_path)\n",
        "\n",
        "          # Annotate unlabeled data with each selected model\n",
        "          print(\"Labeling data with model checkpoint {:s}!\".format(model_path))\n",
        "          unlabeled_logits_and_labels = model_trainer.eval(\n",
        "              sequential_unlabeled_dataloader, is_unlabeled=True,\n",
        "              return_logits=True, pet_samples=True)\n",
        "          logits_from_sampled_models[model_key][\n",
        "              \"logits\"] = unlabeled_logits_and_labels[\"logits\"]\n",
        "          logits_from_sampled_models[model_key][\n",
        "              \"model_init_train_acc\"] = model_pre_training_accuracies[model_key]\n",
        "          logits_from_sampled_models[model_key][\n",
        "              \"eval_labels\"] = unlabeled_logits_and_labels[\"labels\"]\n",
        "\n",
        "        # Merge logits\n",
        "        merged_logits, _ = self._merge_logits(\n",
        "            weighting_strategy, model_logits=logits_from_sampled_models,\n",
        "            for_classifier=False)\n",
        "        # Generate new iPET training data\n",
        "        # Compute number of samples to draw\n",
        "        num_new_pet_samples_per_label = (\n",
        "            self.config.ipet_train_scale_factor - 1) * num_pet_samples_per_label\n",
        "        new_samples, ipet_unlabeled_samples, already_sampled = self._get_next_ipet_data(\n",
        "          merged_logits, num_new_pet_samples_per_label, already_sampled,\n",
        "          zero_shot=True)\n",
        "\n",
        "        # Add new data to previous data\n",
        "        for lk in new_samples.keys():\n",
        "          if lk not in ipet_train_samples.keys():\n",
        "            ipet_train_samples[lk] = new_samples[lk]\n",
        "          else:\n",
        "            ipet_train_samples[lk] += new_samples[lk]\n",
        "        # Update number of iPET samples\n",
        "        num_pet_samples_per_label = self.config.ipet_train_scale_factor * num_pet_samples_per_label\n",
        "\n",
        "\n",
        "  def eval_pet_ensemble(\n",
        "      self,\n",
        "      weighting_strategy\n",
        "      ):\n",
        "\n",
        "    \"\"\" Evaluates the PET ensemble / classifier on the evaluation data. \"\"\"\n",
        "\n",
        "    # Evaluate PET model ensemble\n",
        "    eval_acc = 0\n",
        "    # Combine logits\n",
        "    merged_logits, labels = self._merge_logits(\n",
        "        weighting_strategy, for_classifier=False)\n",
        "    # Compute accuracy\n",
        "    for l_id, lgt in enumerate(merged_logits):\n",
        "      eval_acc += compute_accuracy(\n",
        "          lgt.clone().detach(), torch.tensor(labels[l_id]))\n",
        "    mean_eval_acc = eval_acc / len(merged_logits)\n",
        "    print(\"\\nPET eval complete; mean eval accuracy = {:.3f}\".format(\n",
        "        mean_eval_acc))\n",
        "\n",
        "    return mean_eval_acc\n",
        "\n",
        "\n",
        "  def train_and_eval_pet_classifier(\n",
        "      self,\n",
        "      weighting_strategy\n",
        "      ):\n",
        "\n",
        "    \"\"\" Trains a PET classifier. \"\"\"\n",
        "\n",
        "    # Initialize classifier\n",
        "    model_trainer = SingleModelTrainer(\n",
        "        self.config, self.tokenizer, self.verbalizer, None, None,\n",
        "        train_pet_classifier=True, train_sup_classifier=False)\n",
        "\n",
        "    # Generate classifier data\n",
        "    # Load and merge PET model logits\n",
        "    training_labels, _ = self._merge_logits(\n",
        "        weighting_strategy, for_classifier=True)\n",
        "    # Replace hard labels with soft labels\n",
        "    cls_train_samples = dict()\n",
        "    samples_keys = sorted(list(self.unlabeled_train_samples.keys()))\n",
        "    label_id = 0\n",
        "\n",
        "    for sk in samples_keys:\n",
        "      cls_train_samples[sk] = list()\n",
        "      for smp in self.unlabeled_train_samples[sk]:\n",
        "        new_smp = dict()\n",
        "        for smp_k in smp.keys():\n",
        "          if smp_k != \"label\":\n",
        "            new_smp[smp_k] = smp[smp_k]\n",
        "          else:\n",
        "            new_smp[smp_k] = training_labels[label_id].tolist()\n",
        "        cls_train_samples[sk].append(new_smp)\n",
        "\n",
        "        # # TODO: DEBUGGING\n",
        "        # if label_id + 1 == training_labels.shape[0]:\n",
        "        #   continue\n",
        "        # else:\n",
        "        #   label_id += 1\n",
        "\n",
        "    # Get (non-verbalized) dataloaders\n",
        "    train_cls_dataloader, _, _ = self.data_processor.get_dataloader(\n",
        "        None, cls_train_samples, None, self.config.pet_cls_train_batch_size,\n",
        "        self.config.pet_cls_eval_batch_size, use_mlm_training=False,\n",
        "        is_eval=False, get_sequential_unlabeled_data=False,\n",
        "        no_verbalization=True)\n",
        "\n",
        "    # Train classifier\n",
        "    num_raining_steps, train_loss = model_trainer.train(\n",
        "        train_cls_dataloader, None, use_mlm_training=False)\n",
        "    # Evaluate classifier\n",
        "    logits_and_labels = model_trainer.eval(\n",
        "        self.eval_dataloaders[\"cls\"], is_unlabeled=False, return_logits=False,\n",
        "        pet_samples=False)\n",
        "\n",
        "    return logits_and_labels[\"eval_acc\"]\n",
        "\n",
        "\n",
        "  def train_and_eval_sup_classifier(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    \"\"\" Trains a supervised classifier. \"\"\"\n",
        "\n",
        "    # Initialize classifier\n",
        "    model_trainer = SingleModelTrainer(\n",
        "        self.config, self.tokenizer, self.verbalizer, None, None,\n",
        "        train_pet_classifier=False, train_sup_classifier=True)\n",
        "\n",
        "    if self.num_training_samples > 0:\n",
        "      # Train classifier\n",
        "      train_sup_dataloader, _, _ = self.data_processor.get_dataloader(\n",
        "          None, self.pet_train_samples, None, self.config.cls_train_batch_size,\n",
        "          self.config.cls_eval_batch_size, use_mlm_training=False, is_eval=False,\n",
        "          get_sequential_unlabeled_data=False, no_verbalization=True)\n",
        "      _, _ = model_trainer.train(train_sup_dataloader, None, use_mlm_training=False)\n",
        "\n",
        "    # Evaluate classifier\n",
        "    logits_and_labels = model_trainer.eval(\n",
        "        self.eval_dataloaders[\"cls\"], is_unlabeled=False,\n",
        "        return_logits=False, pet_samples=False)\n",
        "\n",
        "    # Return classifier accuracy\n",
        "    return logits_and_labels[\"eval_acc\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGaDssEaeDMf"
      },
      "outputs": [],
      "source": [
        "# Define experiments\n",
        "\n",
        "# TODO: Add reporting of final results\n",
        "\n",
        "class Experiment(object):\n",
        "  \"\"\" Runs the planned experiments. \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    self.config = Config()\n",
        "    # Set radom seed for reproducibility\n",
        "    self._set_seed()\n",
        "    # Downloads and preprocesses training and evaluation data\n",
        "    print(\"Initializing data getter ...\")\n",
        "    self.data_initializer = DataInitializer(self.config.dataset)\n",
        "    # Initialize tokenizer\n",
        "    print(\"Initializing tokenizer ...\")\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(self.config.checkpoint)\n",
        "    # Initialize verbalizer\n",
        "    print(\"Initializing verbalizer ...\")\n",
        "    self.verbalizer = YelpPVPVerbalizer(self.tokenizer)\n",
        "\n",
        "    # Prepare evaluation data, as it is shared across experiments\n",
        "    self.data_processor = DataProcessor(\n",
        "        self.config, self.data_initializer, self.tokenizer, self.verbalizer)\n",
        "    self.eval_samples = self.data_processor.eval_data_per_label\n",
        "    # Instantiate evaluation dataloaders\n",
        "    self.eval_dataloaders = {\"cls\": None}\n",
        "    cls_eval_dataloader, _, _ = self.data_processor.get_dataloader(\n",
        "          None, self.eval_samples, None, self.config.cls_train_batch_size,\n",
        "          self.config.cls_eval_batch_size, use_mlm_training=False,\n",
        "          is_eval=True, get_sequential_unlabeled_data=False,\n",
        "          no_verbalization=True)\n",
        "    self.eval_dataloaders[\"cls\"] = cls_eval_dataloader\n",
        "\n",
        "\n",
        "  def _set_seed(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    \"\"\" Sets random seed for the used (pseudo-)randomizers \"\"\"\n",
        "\n",
        "    random_seed = random.randint(0,100)\n",
        "    random.seed(random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "\n",
        "  def evaluate_supervised_models(\n",
        "      self,\n",
        "      num_training_samples\n",
        "      ):\n",
        "\n",
        "    \"\"\" Train and evaluate supervised baselines to reproduce paper results. \"\"\"\n",
        "\n",
        "    results = list()\n",
        "    out_dict = dict()\n",
        "    print(\"\\n=== Evaluating baseline supervised classifier for {:d} training examples: ===\".format(\n",
        "        num_training_samples))\n",
        "    for run_id in range(3):  # 3 training runs\n",
        "      print(\"! Training run {:d} !\".format(run_id))\n",
        "\n",
        "      # Reset seed\n",
        "      self._set_seed()\n",
        "\n",
        "      multi_trainer = MultiModelTrainer(self.config,\n",
        "                                        self.data_initializer,\n",
        "                                        self.data_processor,\n",
        "                                        self.tokenizer,\n",
        "                                        self.verbalizer,\n",
        "                                        num_training_samples,\n",
        "                                        self.eval_dataloaders,\n",
        "                                        use_mlm_training=False)\n",
        "\n",
        "      trainer_out = multi_trainer.train_and_eval_sup_classifier()\n",
        "      results.append(trainer_out)\n",
        "      out_dict[\"run_{:d}\".format(run_id)] = trainer_out\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "    print(\"Training samples: {:d} | MAX: {:.1f} | MEAN: {:.1f} (std {:1f})\".format(\n",
        "        num_training_samples, np.max(results), np.mean(results),\n",
        "        np.std(results)))\n",
        "    print(\"Done!\")\n",
        "\n",
        "    return out_dict\n",
        "\n",
        "\n",
        "  def evaluate_pet(\n",
        "      self,\n",
        "      num_pet_samples,\n",
        "      use_mlm,\n",
        "      use_classifier\n",
        "      ):\n",
        "\n",
        "    \"\"\" Evaluates PET models to reproduce paper results. \"\"\"\n",
        "\n",
        "    # Prepare evaluation samples, if neccessary (one per PET pattern)\n",
        "    if len(self.eval_dataloaders.keys()) == 1:\n",
        "      for pattern_id in self.verbalizer.pattern_dict.keys():\n",
        "        self.eval_dataloaders[pattern_id], _, _ = self.data_processor.get_dataloader(\n",
        "          pattern_id, self.eval_samples, None, self.config.train_batch_size,\n",
        "          self.config.eval_batch_size, use_mlm_training=False, is_eval=True,\n",
        "          get_sequential_unlabeled_data=False, no_verbalization=False)\n",
        "\n",
        "    results = list()\n",
        "    out_dict = dict()\n",
        "\n",
        "    print(\"\\n=== Evaluating PET with {:d} PET samples: ===\".format(num_pet_samples))\n",
        "    for run_id in range(3):\n",
        "\n",
        "      # Reset seed\n",
        "      self._set_seed()\n",
        "\n",
        "      multi_trainer = MultiModelTrainer(self.config,\n",
        "                                        self.data_initializer,\n",
        "                                        self.data_processor,\n",
        "                                        self.tokenizer,\n",
        "                                        self.verbalizer,\n",
        "                                        num_pet_samples,\n",
        "                                        self.eval_dataloaders,\n",
        "                                        use_mlm_training=use_mlm)\n",
        "\n",
        "      if use_classifier:\n",
        "        _ = multi_trainer.train_pet_ensemble(\n",
        "            weighting_strategy=\"weighted\", get_unlabeled_logits=True)\n",
        "        trainer_out = multi_trainer.train_and_eval_pet_classifier(\n",
        "            weighting_strategy=\"weighted\")\n",
        "      else:\n",
        "        _ = multi_trainer.train_pet_ensemble(\n",
        "            weighting_strategy=\"weighted\", get_unlabeled_logits=False)\n",
        "        trainer_out = multi_trainer.eval_pet_ensemble(\n",
        "            weighting_strategy=\"weighted\")\n",
        "\n",
        "      out_dict[\"run_{:d}\".format(run_id)] = trainer_out\n",
        "      results.append(trainer_out)\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "    print(\"Training samples: {:d} | Use MLM: {} | MEAN: {:.3f} (std {:3f})\".format(\n",
        "        num_pet_samples, use_mlm, np.mean(results), np.std(results)))\n",
        "    print(\"Done!\")\n",
        "\n",
        "\n",
        "  def ablate_pet(\n",
        "      self\n",
        "      ):\n",
        "\n",
        "    \"\"\" Performs PET ablation studies, required to reproduce Table 4. \"\"\"\n",
        "\n",
        "    # Prepare evaluation samples, if neccessary (one per PET pattern)\n",
        "    if len(self.eval_dataloaders.keys()) == 1:\n",
        "      for pattern_id in self.verbalizer.pattern_dict.keys():\n",
        "        self.eval_dataloaders[pattern_id], _, _ = self.data_processor.get_dataloader(\n",
        "          pattern_id, self.eval_samples, None, self.config.train_batch_size,\n",
        "          self.config.eval_batch_size, use_mlm_training=False, is_eval=True,\n",
        "          get_sequential_unlabeled_data=False, no_verbalization=False)\n",
        "\n",
        "    results_p4 = dict()\n",
        "    print(\"=== Reproducing Table 4 of the paper: ===\")\n",
        "\n",
        "    # Reset seed\n",
        "    self._set_seed()\n",
        "\n",
        "    multi_trainer = MultiModelTrainer(self.config,\n",
        "                                      self.data_initializer,\n",
        "                                      self.data_processor,\n",
        "                                      self.tokenizer,\n",
        "                                      self.verbalizer,\n",
        "                                      10,\n",
        "                                      self.eval_dataloaders,\n",
        "                                      use_mlm_training=True)\n",
        "\n",
        "    trainer_out = multi_trainer.train_pet_ensemble(\n",
        "        weighting_strategy=\"weighted\", get_unlabeled_logits=True)\n",
        "\n",
        "    # Identify best- and worst-performing models\n",
        "    min_model = [100, None, None]\n",
        "    max_model = [0, None, None]\n",
        "\n",
        "    for pattern_id in trainer_out.keys():\n",
        "      for model_id in trainer_out[pattern_id].keys():\n",
        "        if trainer_out[pattern_id][model_id] > max_model[0]:\n",
        "          max_model[0] = trainer_out[pattern_id][model_id]\n",
        "          max_model[1] = pattern_id\n",
        "          max_model[2] = model_id\n",
        "        if trainer_out[pattern_id][model_id] < min_model[0]:\n",
        "          min_model[0] = trainer_out[pattern_id][model_id]\n",
        "          min_model[1] = pattern_id\n",
        "          min_model[2] = model_id\n",
        "\n",
        "    results_p4[\"max_model\"] = \"{:.3f}, pattern {}, model {}\".format(\n",
        "        max_model[0], max_model[1], max_model[2])\n",
        "    results_p4[\"min_model\"] = \"{:.3f}, pattern {}, model {}\".format(\n",
        "        min_model[0], min_model[1], min_model[2])\n",
        "    results_p4[\"no_distillation\"] = multi_trainer.eval_pet_ensemble(\n",
        "        weighting_strategy=\"weighted\")\n",
        "    results_p4[\"pet_uniform\"] = multi_trainer.train_and_eval_pet_classifier(\n",
        "        weighting_strategy=\"uniform\")\n",
        "    results_p4[\"pet_weighted\"] = multi_trainer.train_and_eval_pet_classifier(\n",
        "        weighting_strategy=\"weighted\")\n",
        "\n",
        "    for key in [\"max_model\", \"min_model\", \"no_distillation\",\n",
        "                \"pet_uniform\", \"pet_weighted\"]:\n",
        "      print(\"\\t{} : {}\".format(key, results_p4[key]))\n",
        "\n",
        "    return results_p4\n",
        "\n",
        "\n",
        "  def evaluate_ipet(\n",
        "      self,\n",
        "      num_pet_samples,\n",
        "      use_classifier\n",
        "      ):\n",
        "\n",
        "    \"\"\" Evaluates iPET models to reproduce paper results. \"\"\"\n",
        "\n",
        "    # Prepare evaluation samples, if neccessary (one per PET pattern)\n",
        "    if len(self.eval_dataloaders.keys()) == 1:\n",
        "      for pattern_id in self.verbalizer.pattern_dict.keys():\n",
        "        self.eval_dataloaders[pattern_id], _, _ = self.data_processor.get_dataloader(\n",
        "          pattern_id, self.eval_samples, None, self.config.train_batch_size,\n",
        "          self.config.eval_batch_size, use_mlm_training=False, is_eval=True,\n",
        "          get_sequential_unlabeled_data=False, no_verbalization=False)\n",
        "\n",
        "    results = list()\n",
        "    out_dict = dict()\n",
        "\n",
        "    print(\"\\n=== Evaluating iPET with {:d} PET samples: ===\".format(\n",
        "        num_pet_samples))\n",
        "    for run_id in range(3):\n",
        "\n",
        "      # Reset seed\n",
        "      self._set_seed()\n",
        "\n",
        "      multi_trainer = MultiModelTrainer(self.config,\n",
        "                                        self.data_initializer,\n",
        "                                        self.data_processor,\n",
        "                                        self.tokenizer,\n",
        "                                        self.verbalizer,\n",
        "                                        num_pet_samples,\n",
        "                                        self.eval_dataloaders,\n",
        "                                        use_mlm_training=True)\n",
        "\n",
        "      if use_classifier:\n",
        "        _ = multi_trainer.train_ipet_ensemble(\n",
        "            weighting_strategy=\"weighted\", get_unlabeled_logits=True)\n",
        "        trainer_out = multi_trainer.train_and_eval_pet_classifier(\n",
        "            weighting_strategy=\"weighted\")\n",
        "      else:\n",
        "        _ = multi_trainer.train_ipet_ensemble(\n",
        "            weighting_strategy=\"weighted\", get_unlabeled_logits=False)\n",
        "        trainer_out = multi_trainer.eval_pet_ensemble(\n",
        "            weighting_strategy=\"weighted\")\n",
        "\n",
        "      out_dict[\"run_{:d}\".format(run_id)] = trainer_out\n",
        "      results.append(trainer_out)\n",
        "\n",
        "    print(\"-\" * 20)\n",
        "    print(\"Training samples: {:d} | MEAN: {:.3f} (std {:3f})\".format(\n",
        "          num_pet_samples, np.mean(results), np.std(results)))\n",
        "    print(\"Done!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71H3b92BDSJL"
      },
      "outputs": [],
      "source": [
        "# Run experiments\n",
        "exp = Experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lxftYCfX3vz1"
      },
      "outputs": [],
      "source": [
        "# Supervised models\n",
        "runs = dict()\n",
        "training_set_sizes = [0, 10, 50, 100, 1000]\n",
        "for num_training_samples in training_set_sizes:\n",
        "  runs[num_training_samples] = exp.evaluate_supervised_models(\n",
        "      num_training_samples)\n",
        "\n",
        "print(\"=\" * 100)\n",
        "for tss in training_set_sizes:\n",
        "  print(\"{} : {}\".format(tss, runs[tss]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MUINksy37dg"
      },
      "outputs": [],
      "source": [
        "# PET\n",
        "runs = dict()\n",
        "training_set_sizes = [10, 50, 100, 1000]\n",
        "for num_pet_samples in training_set_sizes:\n",
        "  runs[num_pet_samples] = dict()\n",
        "  for use_mlm in [True, False]:\n",
        "    runs[num_pet_samples][str(use_mlm)] = exp.evaluate_pet(\n",
        "        num_pet_samples, use_mlm, use_classifier=True)\n",
        "\n",
        "print(\"=\" * 100)\n",
        "for tss in training_set_sizes:\n",
        "  print(\"{} : {}\".format(tss, runs[tss]))\n",
        "\n",
        "# Plot reproduction of Figure 3\n",
        "x = np.array(training_set_sizes)\n",
        "y = np.array(\n",
        "    [runs[tss][\"True\"] - runs[tss][\"False\"] for tss in training_set_sizes])\n",
        "plt.plot(x, y, color='blue', marker='o', label=\"Yelp\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Improvements\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ChrjyTY4DGE"
      },
      "outputs": [],
      "source": [
        "exp.ablate_pet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqXEhfFb4KTd"
      },
      "outputs": [],
      "source": [
        "# iPET\n",
        "runs = dict()\n",
        "training_set_sizes = [0, 10, 50, 100]\n",
        "for num_pet_samples in training_set_sizes:\n",
        "  runs[num_pet_samples] = exp.evaluate_ipet(\n",
        "      num_pet_samples, use_classifier=True)\n",
        "\n",
        "print(\"=\" * 100)\n",
        "for tss in training_set_sizes:\n",
        "  print(\"{} : {}\".format(tss, runs[tss]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPq4UT+CFltqWR0teEiMWoj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}